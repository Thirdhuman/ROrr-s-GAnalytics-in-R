split_6=split_url_vector[[6]]
split_7=split_url_vector[[7]]
split_8=split_url_vector[[8]]
split_9=split_url_vector[[9]]
split_10=split_url_vector[[10]]
split_11=split_url_vector[[11]]
split_12=split_url_vector[[12]]
split_13=split_url_vector[[13]]
split_14=split_url_vector[[14]]
split_15=split_url_vector[[15]]
split_16=split_url_vector[[16]]
responses_1 <- pbmclapply(split_1, SafeGet, mc.preschedule=T)
responses_2 <- pbmclapply(split_2, SafeGet, mc.preschedule=T)
SafeGet = function (x)	{
tryCatch({
#	short_url_vector
html=GET(x)
parsed=htmlParse(html)
root=xmlRoot(parsed)
title = xpathSApply(root, "//h1[@class='page-h1'][1]", xmlValue)
return(title)
Sys.sleep(.5)},
error=function(e){cat("ERROR :", conditionMessage(e))}, '0')}
responses_3 <- pbmclapply(split_3, SafeGet, mc.preschedule=T)
responses_4 <- pbmclapply(split_4, SafeGet, mc.preschedule=T)
responses_5 <- pbmclapply(split_5, SafeGet, mc.preschedule=T)
responses_6 <- pbmclapply(split_6, SafeGet, mc.preschedule=T)
responses_7 <- pbmclapply(split_7, SafeGet, mc.preschedule=T)
SafeGet = function (x)	{
tryCatch({
#	short_url_vector
html=GET(x)
parsed=htmlParse(html)
root=xmlRoot(parsed)
title = xpathSApply(root, "//h1[@class='page-h1'][1]", xmlValue)
return(title)
Sys.sleep(.25)},
error=function(e){cat("ERROR :", conditionMessage(e))}, '0')}
responses_8 <- pbmclapply(split_8, SafeGet, mc.preschedule=T)
responses_9 <- pbmclapply(split_9, SafeGet, mc.preschedule=T)
responses_16 <- pbmclapply(split_16, SafeGet, mc.preschedule=T)
save(responses_1, file = "responses_1.RData")
save(responses_2, file = "responses_2.RData")
save(responses_3, file = "responses_3.RData")
save(responses_4, file = "responses_4.RData")
save(responses_5, file = "responses_5.RData")
save(responses_6, file = "responses_6.RData")
save(responses_7, file = "responses_7.RData")
save(responses_8, file = "responses_8.RData")
save(responses_9, file = "responses_9.RData")
save(responses_16, file = "responses_16.RData")
responses_10 <- pbmclapply(split_10, SafeGet, mc.preschedule=T)
responses_11 <- pbmclapply(split_11, SafeGet, mc.preschedule=T)
responses_12 <- pbmclapply(split_12, SafeGet, mc.preschedule=T)
responses_13 <- pbmclapply(split_13, SafeGet, mc.preschedule=T)
responses_14 <- pbmclapply(split_14, SafeGet, mc.preschedule=T)
responses_15 <- pbmclapply(split_15, SafeGet, mc.preschedule=T)
save(responses_1, file = "responses_1.RData")
save(responses_2, file = "responses_2.RData")
save(responses_3, file = "responses_3.RData")
save(responses_4, file = "responses_4.RData")
save(responses_5, file = "responses_5.RData")
save(responses_6, file = "responses_6.RData")
save(responses_7, file = "responses_7.RData")
save(responses_8, file = "responses_8.RData")
save(responses_9, file = "responses_9.RData")
save(responses_10, file = "responses_10.RData")
save(responses_11, file = "responses_11.RData")
save(responses_12, file = "responses_12.RData")
save(responses_13, file = "responses_13.RData")
save(responses_14, file = "responses_14.RData")
save(responses_15, file = "responses_15.RData")
save(responses_16, file = "responses_16.RData")
website_responses=lapply(c(responses_1,responses_2,responses_3,responses_4,responses_5,responses_6,responses_7,
responses_8,responses_9,responses_10,responses_11, responses_12,responses_13,responses_14,responses_15,responses_16),as.character)
View(website_responses)
View(responses_1)
View(split_6)
View(split_1)
#### Split ####
library(stringdist)
require(XML)
library(data.table)
url_1=download_xml('https://www.cato.org/sitemap.xml?page=1')
url_2=download_xml('https://www.cato.org/sitemap.xml?page=2')
# Read XML 1
xmlfile <- xmlParse(url_1)
# Convert to List
tagsList <- xmlToList(xmlfile)
# Each List element is a character vector.  Convert each of these into a data.table
tagsList <- lapply(tagsList, function(x) as.data.table(as.list(x)))
# Rbind all the 1-row data.tables into a single data.table
tags_1 <- rbindlist(tagsList, use.names = T, fill = T)
tags_1=as.data.frame(tags_1)
# Read XML 2
xmlfile <- xmlParse(url_2)
# Convert to List
tagsList <- xmlToList(xmlfile)
# Each List element is a character vector.  Convert each of these into a data.table
tagsList <- lapply(tagsList, function(x) as.data.table(as.list(x)))
# Rbind all the 1-row data.tables into a single data.table
tags_2 <- rbindlist(tagsList, use.names = T, fill = T)
tags_2=as.data.frame(tags_2)
url_list=as.list(rbind(tags_2$loc, tags_2$loc))
url_vector=as.vector(url_list)
split_url_vector = split(url_vector, ceiling(seq_along(url_vector)/4000))
split_1=split_url_vector[[1]]
website_responses=unique(website_responses)
View(website_responses)
website_responses=(c(responses_1,responses_2,responses_3,responses_4,responses_5,responses_6,responses_7,
responses_8,responses_9,responses_10,responses_11, responses_12,responses_13,responses_14,responses_15,responses_16))
View(website_responses)
View(split_14)
split_1=split_url_vector[[1]]
View(split_1)
url_vector
url_list=as.list(rbind(tags_2$loc, tags_2$loc))
url_list
tags_2
tagsList
View(tagsList)
tagsList[["url"]]
tagsList[["url"]]
tagsList[["url"]]
tagsList[["url"]]
tagsList
tagsList <- xmlToList(xmlfile)
View(tagsList)
View(tags_1)
View(tags_2)
url_list=as.list(rbind(tags_1$loc, tags_2$loc))
url_list=as.list(cbind(tags_1$loc, tags_2$loc))
url_list=as.list(rbind(tags_1$loc, tags_2$loc))
View(tags_1)
View(tags_2)
url_vector=as.vector(url_list)
split_url_vector = split(url_vector, ceiling(seq_along(url_vector)/4000))
View(split_url_vector)
url_vector=as.vector(url_list)
split_url_vector = split(url_vector, ceiling(seq_along(url_vector)/4000))
tags_2=as.data.frame(tags_2)
url_list=as.list(rbind(tags_1$loc, tags_2$loc))
url_vector=as.vector(url_list)
split_url_vector = split(url_vector, ceiling(seq_along(url_vector)/4000))
View(split_url_vector)
View(url_list)
tags_2=as.data.frame(tags_2)
url_list=as.list(rbind(tags_1$loc, tags_2$loc))
url_vector=as.vector(url_list)
split_url_vector = split(url_vector, ceiling(seq_along(url_vector)/4000))
split_1=split_url_vector[[1]]
split_2=split_url_vector[[2]]
split_3=split_url_vector[[3]]
split_4=split_url_vector[[4]]
split_5=split_url_vector[[5]]
split_6=split_url_vector[[6]]
split_7=split_url_vector[[7]]
split_8=split_url_vector[[8]]
split_9=split_url_vector[[9]]
split_10=split_url_vector[[10]]
split_11=split_url_vector[[11]]
split_12=split_url_vector[[12]]
split_13=split_url_vector[[13]]
split_14=split_url_vector[[14]]
split_15=split_url_vector[[15]]
split_16=split_url_vector[[16]]
#### Apply ####
SafeGet = function (x)	{
tryCatch({
#	short_url_vector
html=GET(x)
parsed=htmlParse(html)
root=xmlRoot(parsed)
title = xpathSApply(root, "//h1[@class='page-h1'][1]", xmlValue)
return(title)
Sys.sleep(.25)},
error=function(e){cat("ERROR :", conditionMessage(e))}, '0')}
responses_1 <- pbmclapply(split_1, SafeGet, mc.preschedule=T)
View(url_list)
#### Split ####
library(stringdist)
require(XML)
library(data.table)
url_1=download_xml('https://www.cato.org/sitemap.xml?page=1')
url_2=download_xml('https://www.cato.org/sitemap.xml?page=2')
# Read XML 1
xmlfile <- xmlParse(url_1)
# Convert to List
tagsList <- xmlToList(xmlfile)
# Each List element is a character vector.  Convert each of these into a data.table
tagsList <- lapply(tagsList, function(x) as.data.table(as.list(x)))
# Rbind all the 1-row data.tables into a single data.table
tags_1 <- rbindlist(tagsList, use.names = T, fill = T)
tags_1=as.data.frame(tags_1)
# Read XML 2
xmlfile <- xmlParse(url_2)
# Convert to List
tagsList <- xmlToList(xmlfile)
# Each List element is a character vector.  Convert each of these into a data.table
tagsList <- lapply(tagsList, function(x) as.data.table(as.list(x)))
# Rbind all the 1-row data.tables into a single data.table
tags_2 <- rbindlist(tagsList, use.names = T, fill = T)
tags_2=as.data.frame(tags_2)
url_list=as.list(rbind(tags_1$loc, tags_2$loc))
url_vector=as.vector(url_list)
split_url_vector = split(url_vector, ceiling(seq_along(url_vector)/4000))
View(split_url_vector)
split_url_vector = split(url_vector, ceiling(seq_along(url_vector)/5000))
split_url_vector = split(url_vector, ceiling(seq_along(url_vector)/5000))
split_1=split_url_vector[[1]]
split_2=split_url_vector[[2]]
split_3=split_url_vector[[3]]
split_4=split_url_vector[[4]]
split_5=split_url_vector[[5]]
split_6=split_url_vector[[6]]
split_7=split_url_vector[[7]]
split_8=split_url_vector[[8]]
split_9=split_url_vector[[9]]
split_10=split_url_vector[[10]]
split_11=split_url_vector[[11]]
split_12=split_url_vector[[12]]
split_13=split_url_vector[[13]]
split_14=split_url_vector[[14]]
split_15=split_url_vector[[15]]
SafeGet = function (x)	{
tryCatch({
#	short_url_vector
html=GET(x)
parsed=htmlParse(html)
root=xmlRoot(parsed)
title = xpathSApply(root, "//h1[@class='page-h1'][1]", xmlValue)
return(title)
Sys.sleep(.25)},
error=function(e){cat("ERROR :", conditionMessage(e))}, '0')}
responses_1 <- pbmclapply(split_1, SafeGet, mc.preschedule=T)
responses_2 <- pbmclapply(split_2, SafeGet, mc.preschedule=T)
responses_3 <- pbmclapply(split_3, SafeGet, mc.preschedule=T)
responses_3 <- pbmclapply(split_3, SafeGet, mc.preschedule=T)
responses_4 <- pbmclapply(split_4, SafeGet, mc.preschedule=T)
responses_5 <- pbmclapply(split_5, SafeGet, mc.preschedule=T)
responses_6 <- pbmclapply(split_6, SafeGet, mc.preschedule=T)
responses_7 <- pbmclapply(split_7, SafeGet, mc.preschedule=T)
responses_8 <- pbmclapply(split_8, SafeGet, mc.preschedule=T)
responses_9 <- pbmclapply(split_9, SafeGet, mc.preschedule=T)
responses_10 <- pbmclapply(split_10, SafeGet, mc.preschedule=T)
responses_11 <- pbmclapply(split_11, SafeGet, mc.preschedule=T)
responses_12 <- pbmclapply(split_12, SafeGet, mc.preschedule=T)
responses_13 <- pbmclapply(split_13, SafeGet, mc.preschedule=T)
responses_14 <- pbmclapply(split_14, SafeGet, mc.preschedule=T)
responses_15 <- pbmclapply(split_15, SafeGet, mc.preschedule=T)
save(responses_1, file = "responses_1.RData")
save(responses_2, file = "responses_2.RData")
save(responses_3, file = "responses_3.RData")
save(responses_4, file = "responses_4.RData")
save(responses_5, file = "responses_5.RData")
save(responses_6, file = "responses_6.RData")
save(responses_7, file = "responses_7.RData")
save(responses_8, file = "responses_8.RData")
save(responses_9, file = "responses_9.RData")
save(responses_10, file = "responses_10.RData")
save(responses_11, file = "responses_11.RData")
save(responses_12, file = "responses_12.RData")
save(responses_13, file = "responses_13.RData")
save(responses_14, file = "responses_14.RData")
save(responses_15, file = "responses_15.RData")
website_responses=(c(responses_1,responses_2,responses_3,responses_4,responses_5,responses_6,responses_7,
responses_8,responses_9,responses_10,responses_11, responses_12,responses_13,responses_14,responses_15))
View(responses_15)
website_responses=lapply(c(responses), as.character)
is.na(website_responses) = lengths(website_responses) == 0
website_responses[lengths(website_responses) == 0] = NA
title=trimws(website_responses)
link_df=as.data.frame(cbind(title=title, pagePath=url_vector))
link_df_full=as.data.frame(cbind(pagePath=url_vector_full))
title=trimws(website_responses)
link_df=as.data.frame(cbind(title=title, pagePath=url_vector))
website_responses=lapply(c(responses), as.character)
is.na(website_responses) = lengths(website_responses) == 0
website_responses[lengths(website_responses) == 0] = NA
title=trimws(website_responses)
link_df=as.data.frame(cbind(title=title, pagePath=url_vector))
############# Load and Save #################
save(link_df, file = "sitemap.RData")
View(link_df)
View(link_df)
test=na.omit(link_df)
View(test)
website_responses=lapply(c(responses), as.character)
is.na(website_responses) = lengths(website_responses) == 0
website_responses[lengths(website_responses) == 0] = 0
title=trimws(website_responses)
link_df=as.data.frame(cbind(title=title, pagePath=url_vector))
test=na.omit(link_df)
website_responses=(c(responses_1,responses_2,responses_3,responses_4,responses_5,responses_6,responses_7,
responses_8,responses_9,responses_10,responses_11, responses_12,responses_13,responses_14,responses_15))
website_responses=lapply(c(responses), as.character)
is.na(website_responses) = lengths(website_responses) == 0
website_responses[lengths(website_responses) == 0] = NA
title=trimws(website_responses)
link_df=as.data.frame(cbind(title=title, pagePath=url_vector))
test=na.omit(link_df)
View(test)
test=na.omit(link_df$title)
View(test)
test<-link_df[!is.na(link_df$title), ]
View(test)
View(test)
test<-link_df[-which(is.na(link_df$title)),]
View(test)
website_responses=(c(responses_1,responses_2,responses_3,responses_4,responses_5,responses_6,responses_7,
responses_8,responses_9,responses_10,responses_11, responses_12,responses_13,responses_14,responses_15))
is.na(website_responses) = lengths(website_responses) == 0
website_responses[lengths(website_responses) == 0] = NA
title=trimws(website_responses)
link_df=as.data.frame(cbind(title=title, pagePath=url_vector))
test<-link_df[-which(is.na(link_df$title)),]
View(test)
website_responses=(c(responses_1,responses_2,responses_3,responses_4,responses_5,responses_6,responses_7,
responses_8,responses_9,responses_10,responses_11, responses_12,responses_13,responses_14,responses_15))
is.na(website_responses) = lengths(website_responses) == 0
website_responses[lengths(website_responses) == 0] = NA
title=trimws(website_responses)
link_df=as.data.frame(cbind(title=title, pagePath=url_vector))
test<-link_df[which(!is.na(link_df$title)),]
test<-link_df[which(is.na(link_df$title)),]
website_responses=(c(responses_1,responses_2,responses_3,responses_4,responses_5,responses_6,responses_7,
responses_8,responses_9,responses_10,responses_11, responses_12,responses_13,responses_14,responses_15))
is.na(website_responses) = lengths(website_responses) == 0
website_responses[lengths(website_responses) == 0] = NA
title=trimws(website_responses)
link_df=as.data.frame(cbind(title=title, pagePath=url_vector))
test<-link_df[-which(is.na(link_df$title)),]
View(link_df)
website_responses=(c(responses_1,responses_2,responses_3,responses_4,responses_5,responses_6,responses_7,
responses_8,responses_9,responses_10,responses_11, responses_12,responses_13,responses_14,responses_15))
title=trimws(website_responses)
link_df=as.data.frame(cbind(title=title, pagePath=url_vector))
test<-link_df[-which(is.na(link_df$title)),]
website_responses=(c(responses_1,responses_2,responses_3,responses_4,responses_5,responses_6,responses_7,
responses_8,responses_9,responses_10,responses_11, responses_12,responses_13,responses_14,responses_15))
title=trimws(website_responses)
link_df=as.data.frame(cbind(title=title, pagePath=url_vector))
is.na(link_df) = lengths(link_df) == 0
link_df[lengths(link_df) == 0] = NA
test<-link_df[-which(is.na(link_df$title)),]
View(test)
test<-link_df[-which(is.na(link_df$title)),]
test<-link_df[-which(is.na(link_df)),]
test <-  link_df[complete.cases(link_df), ]
test <-  link_df[complete.cases(link_df$title), ]
View(test)
website_responses=(c(responses_1,responses_2,responses_3,responses_4,responses_5,responses_6,responses_7,
responses_8,responses_9,responses_10,responses_11, responses_12,responses_13,responses_14,responses_15))
is.na(website_responses) = lengths(website_responses) == 0
website_responses[lengths(website_responses) == 0] = NA
title=trimws(website_responses)
link_df=as.data.frame(cbind(title=title, pagePath=url_vector))
test <-  link_df[complete.cases(link_df$title), ]
View(test)
test<-link_df[-which(link_df$title == NA),]
View(test)
test<-link_df[-which(is.na(link_df$title == "NA")),]
test<-link_df[-which((link_df$title == "NA")),]
View(test)
load( file = "Big_Raw_GA_DAT.RData")
setwd("~/Desktop/Welfare_Policy/Data/Data_Explorations/Google_Analytics(Cato)")
# Fonts
library(extrafont)
font_import()
getwd()
# My Packages
library(googleAnalyticsR)
library(tidyverse)
library(httr)
library(RCurl)
library(XML)
library(foreach)
library(stringr)
library(ggplot2)
library(data.table)
library(stringdist)
library(pbmcapply)
library(openxlsx)
#library(plyr)
##########################################################################################
###################################### Begin script ######################################
##########################################################################################
# Define Date
current_date=format(Sys.time(), "%Y-%m-%d")
current_date=as.Date(current_date)
# Open Google Analytics
account_list <- ga_account_list()
ga_id <- account_list$viewId[1]
cato_scholars=read.xlsx('Cato_Scholars.xlsx')
# Choose person(s) of interest
targets = cato_scholars %>% filter(str_detect(name.website, 'Vanessa'))
name=targets$name.website
name=as.character(name)
last_name=str_extract(name,'[^ ]+$')
authur_row=as.data.frame(cato_scholars$name.website)
colnames(authur_row) = authur_row[1, ] # the first row will be the header
authur_row = authur_row[-1, ]          # removing the first row.
authur_row=as.vector(as.character(authur_row))
# Establish date range
from <- "2014-07-01" # (Earliest Available)
#from <- "2018-7-14" # (Insert Other)
to   <- as.character(current_date)
#### create filters on dimensions ####
dimf <- dim_filter("dimension1","PARTIAL", expressions=name,not = F, caseSensitive = F)
dimf2 <- dim_filter("countryIsoCode","EXACT","US",not = F)
fc2 <- filter_clause_ga4(list(# dimf #,dimf2
), operator = "OR")
#### Construct File Name ####
from_s = (from)
from_m = as.character(from)
from_y=str_sub(from, start=3, end = 4)
from_m=str_sub(from, start=6, end = 7)
to_y=str_sub(to, start=3, end = 4)
to_m=str_sub(to, start=6, end = 7)
analysis_range=paste0("(",from_m,from_y,'-',to_m,to_y,")")
initials <- function(a, b){
a <- str_split(a, "&")
a1 <- lapply(a, function(x){
x1 <- str_split(str_trim(x), " ")
paste0(unlist(lapply(x1, str_sub, 1, 2)), collapse="")	})
paste0(unlist(a1), b) }
analysis_identifier=initials(name,analysis_range)
#### Specify Search terms ####
max = 500000000
met = c("sessions", #"pageviews",
'timeOnPage','avgTimeOnPage',
"entrances","bounces", 'exitRate')
dim = c("date", 'pageTitle',
"ga:dimension1", #'channelGrouping',# 'city', 'region',
#'ga:dimension2',
'pagePath')
#lst <- sapply(str_extract_all(name), function(x) substr(x, 0, 2))
# view id of your Google Analytics view where 1 conversion = visit
vid <- "3016983"
#### Launch Google Analytic Retrieval Function ####
get_data=function(vid,from,to,dim,met,max){df=google_analytics(
viewId=vid,date_range=c(from,to),metrics=met,dimensions=dim, #met_filters = fc,
dim_filters = fc2,  max = max	,anti_sample = TRUE)
# clean up and set class
df$dimension1 = gsub('O&#039;Toole', "O'Toole", df$dimension1)
df$dimension1 = gsub('&quot;Chip&quot;', "\"Chip\"", df$dimension1)
df$author_full=df$dimension1
df$dimension1 <- NULL
df}
gadata=get_data(vid=vid, from=from, to=to, dim=dim, met=met, max=max)
df1 = as.data.frame(gadata)
names(df1)
df1$pageTitle <- gsub("([ | ].*)[ | ] .*", "\\1", df1$pageTitle)
df1$pageTitle <- sub(" | .*","",df1$pageTitle)
unique(df1$author_full)
print(unique(df1$author_full))
print(unique(df1$author_full))[1]
gadata$author_full = gsub('&quot;Chip&quot;', "'Chip'", gadata$dimension1)
gadata$author_full = gsub('&quot;Chip&quot;', "'Chip'", gadata$author_full)
gadata$author_full = gsub("\"Chip\"", "'Chip'", gadata$author_full)
print(unique(df1$author_full)
df1 = as.data.frame(gadata)
df1 = as.data.frame(gadata)
print(unique(df1$author_full)
)
df1 = as.data.frame(gadata)
names(df1)
df1$pageTitle <- gsub("([ | ].*)[ | ] .*", "\\1", df1$pageTitle)
View(df1)
count((df1$author_full == "401"))
length((df1$author_full == "401"))
((df1$author_full == "401"))
authurs=unique(df1$author_full)
authurs=as.data.frame(unique(df1$author_full))
View(authurs)
authurs=is.numeric(unique(df1$author_full == 34))
authurs=is.numeric(unique(df1$author_full))
authurs=df1[!is.na(as.numeric(df1$author_full)), ]
View(authurs)
df2=!df1[!is.na(as.numeric(df1$author_full)), ]
authurs=df1[-which(!is.na(as.numeric(df1$author_full))),]
df1=df1[-which(!is.na(as.numeric(df1$author_full))),]
df1 = as.data.frame(gadata)
df1=df1[-which(!is.na(as.numeric(df1$author_full))),]
df1$pageTitle <- gsub("([ | ].*)[ | ] .*", "\\1", df1$pageTitle)
View(df1)
authurs=subset(df1, select(author_full))
authurs=subset(df1, unique(author_full) select(c(author_full)))
authurs=unique(df1$author_full)
source('~/Desktop/Welfare_Policy/Data/Data_Explorations/Google_Analytics(Cato)/All_authors.R', echo=TRUE)
authurs=as.list(unique(df1$author_full))
View(authurs)
authurs[[1190]]
save(df1, file = "Big_Raw_GA_DAT.RData")
save(title, file = "Big_Title_Vector.RData")
save(linked_title, file = "Big_LinkedTitle.RData")
save(link_df, file = "sitemap.RData")
save(responses_1, file = "responses_1.RData")
save(responses_2, file = "responses_2.RData")
save(responses_3, file = "responses_3.RData")
save(responses_4, file = "responses_4.RData")
save(responses_5, file = "responses_5.RData")
save(responses_6, file = "responses_6.RData")
save(responses_7, file = "responses_7.RData")
save(responses_8, file = "responses_8.RData")
save(responses_9, file = "responses_9.RData")
save(responses_10, file = "responses_10.RData")
save(responses_11, file = "responses_11.RData")
save(responses_12, file = "responses_12.RData")
save(responses_13, file = "responses_13.RData")
save(responses_14, file = "responses_14.RData")
save(responses_15, file = "responses_15.RData")
