z=update(z, i_stat_f = factor( i_stat )) # Define Factor
z=update(z,i_gen_kids= ifelse(prcitshp!=5&either_parent_immigrant==0,1,ifelse(prcitshp!=5&either_parent_immigrant==1,2,ifelse(prcitshp==5,3,0))))
z=update(z, i_gen_stat = ifelse(prcitshp >= 4, 1,ifelse(i_parent== 1, 2,ifelse(i_parent == 0, 3, 0)))) # Generational Stat
z=update(z,kid_stat_old= ifelse(prcitshp<=3&either_parent_noncitizen==0,1,
ifelse(prcitshp<=4&either_parent_noncitizen==1,2,
ifelse(prcitshp==5,3,0))))
# Uninsured vs. Insured
z=update(z, uninsure = ifelse( ahiper == 0, 0, ifelse(ahiper >= 1, 1, 0)))
# Supplemental Security Income
z=update(z, ssi = ifelse( ssi_yn == 1, 1, ifelse(ssi_yn == 2, 0, 0)))
# Recieve TANF
z=update(z, pub_help = ifelse( paw_yn == 1, 1, ifelse(paw_yn == 2, 0, 0)))
# Average SNAP Benefit per person
z=update(z, avgsnapben = hfdval/h_numper)
# Recieve FoodStamp
z=update(z, snap_count = ifelse( hfoodsp == 1, 1, ifelse(hfoodsp == 2, 0, 0)))
# Supplemental Security Income
z=update(z, ssi_count = ifelse( ssi_yn == 1, 1, ifelse(ssi_yn == 2, 0, 0)))
# Social Security Count
z=update(z, ss_count = ifelse( ss_yn == 1, 1, ifelse(ss_yn == 0, 0, 0)))
# Diverse Government Care Stat
z=update(z,govcare=ifelse((z$ch_mc==1&z$a_age < 15)|( z$pchip==1)|(z$caid==1&z$a_age >=15)|(z$mcaid ==1&z$a_age>=15),1,0))
#### Populations ####
# Non Poverty
adults=subset(z, a_age > 18 )
child=subset(z, a_age <= 18 )
elderly=subset(z, a_age >= 65)
adults_Im=subset(z, a_age > 17 & i_stat == 3)
# Poverty
pov200=subset(z, povll < 8)
pov200_a=subset(z, povll < 8&a_age > 18 )
pov200_c=subset(z, povll < 8&a_age <= 17 )
pov200_e=subset(z, povll < 8&a_age >= 65)
svyby( ~one, by = ~ i_cit_stat, design =adults, FUN=svytotal)
svyby( ~one, by = ~ kid_stat_old, design =child, FUN=svytotal)
z=update(z,kid_stat_old= ifelse(prcitshp!=5&either_parent_noncitizen==0,1,
ifelse(prcitshp!=5&either_parent_noncitizen==1,2,
ifelse(prcitshp==5,3,0))))
# Uninsured vs. Insured
z=update(z, uninsure = ifelse( ahiper == 0, 0, ifelse(ahiper >= 1, 1, 0)))
# Supplemental Security Income
z=update(z, ssi = ifelse( ssi_yn == 1, 1, ifelse(ssi_yn == 2, 0, 0)))
# Recieve TANF
z=update(z, pub_help = ifelse( paw_yn == 1, 1, ifelse(paw_yn == 2, 0, 0)))
# Average SNAP Benefit per person
z=update(z, avgsnapben = hfdval/h_numper)
# Recieve FoodStamp
z=update(z, snap_count = ifelse( hfoodsp == 1, 1, ifelse(hfoodsp == 2, 0, 0)))
# Supplemental Security Income
z=update(z, ssi_count = ifelse( ssi_yn == 1, 1, ifelse(ssi_yn == 2, 0, 0)))
# Social Security Count
z=update(z, ss_count = ifelse( ss_yn == 1, 1, ifelse(ss_yn == 0, 0, 0)))
# Diverse Government Care Stat
z=update(z,govcare=ifelse((z$ch_mc==1&z$a_age < 15)|( z$pchip==1)|(z$caid==1&z$a_age >=15)|(z$mcaid ==1&z$a_age>=15),1,0))
#### Populations ####
# Non Poverty
adults=subset(z, a_age > 18 )
child=subset(z, a_age <= 18 )
elderly=subset(z, a_age >= 65)
adults_Im=subset(z, a_age > 17 & i_stat == 3)
# Poverty
pov200=subset(z, povll < 8)
pov200_a=subset(z, povll < 8&a_age > 18 )
pov200_c=subset(z, povll < 8&a_age <= 17 )
pov200_e=subset(z, povll < 8&a_age >= 65)
svyby( ~one, by = ~ i_cit_stat, design =adults, FUN=svytotal)
svyby( ~one, by = ~ kid_stat_old, design =child, FUN=svytotal)
library(rjson)
library(twitteR)
library(ROAuth)
library(httr)
library(XML)
library(anytime)
library(syuzhet)
#library(reticulate)
#os <- import("os")
# Set API Keys
access_token   =   '3705111012-0ZSGhm0Y5XDkptTYfecD8TwXoJTepfQ6fgtkUX2'
access_token_secret  =  'i3EaK25UsGsHvnhJzvyLxTnVOAMusH5giu0oOKf3Y0pJY'
consumer_key = 'kI3TDGtYDpdN5mPWVtZg4E74L'
consumer_secret  = 'Lk9upIVEm5BsiQq1o3KalWDWLxHL2hFnRlzwDJAkIGnSUvkr6Y'
setup_twitter_oauth(consumer_key, consumer_secret,access_token, access_token_secret)
cato_feeds= 'cato-twitter-feeds'
twlist= "cato-policy-scholars"
twowner= "CatoInstitute"
api.url= paste0("https://api.twitter.com/1.1/lists/members.json?slug=",twlist,"&owner_screen_name=",twowner,"&count=5000")
response <- GET(api.url, config(token=twitteR:::get_oauth_sig()))
response
#cato-twitter-feeds
response.list <- fromJSON(content(response, as = "text", encoding = "UTF-8"))
users.names <- sapply(response.list$users, function(i) i$name)
users.screennames <- sapply(response.list$users, function(i) i$screen_name)
users.IDs <- sapply(response.list$users, function(i) i$id_str)
faves <- sapply(response.list$users, function(i) i$favourites_count)
followers <- sapply(response.list$users, function(i) i$followers_count)
date_created <- sapply(response.list$users, function(i) i$created_at)
cato_twitter=cbind(users.names,date_created,users.screennames,users.IDs,faves,followers)
cato_twitter
write.csv(cato_twitter, "scholar_media.csv")
write.csv(cato_twitter, "Cato_Scholars.csv")
read.csv(Cato_Scholars.csv)
read.csv('Cato_Scholars.csv')
scholars=read.csv('Cato_Scholars.csv')
scholars
library(stringdist)
name="Michael D. Tanner"
ClosestMatch2 = function(string, stringVector){
stringVector[amatch(string, stringVector, maxDist=Inf)]}
ClosestMatch2(name, scholars$users.names)
scholars$name.website=NA
View(scholars)
max = 4000
met = c("sessions",
#"pageviews",
'timeOnPage','avgTimeOnPage',
"entrances","bounces", 'exitRate')
dim = c("date",
"ga:dimension1",
#'ga:dimension2',
#'region',
#'city',
'pagePath'
)
# the function
df2 = data.frame()
get_data <- function(vid, from, to, dim, met, max) {
df <- google_analytics(viewId = vid, date_range = c(from, to), metrics = met,  dimensions = dim,
#met_filters = fc,
dim_filters = fc2,  max = max	,anti_sample = TRUE)
# clean up and set class
df$dimension1 = gsub('O&#039;Toole', "O'Toole", df$dimension1)
df$author_full=df$dimension1
df$dimension1 <- NULL
df$author=name
df$co_authors = gsub(name, '', df$author_full)
df$co_authors = gsub("^,*|(?<=,),|,*$", "", df$co_authors, perl=T)
df$co_authors=gsub(', , ', ', ', df$co_authors)
df$co_authors=trimws(df$co_authors)
df$collaboration_yn=ifelse(df$author==df$author_full,"Sole Author",
ifelse(df$author!=df$author_full|!is.na(df$co_authors),"Co-Authored",0))
df}
gadata <- get_data(vid=vid, from=from, to=to, dim=dim, met=met, max=max)
setwd("~/Desktop/Welfare_Policy/Data/Data_Explorations/Google_Analytics(Cato)")
# Fonts
library(extrafont)
font_import()
getwd()
# My Packages
library(googleAnalyticsR)
library(dplyr)
library(httr)
library(RCurl)
library(XML)
library(foreach)
library(stringr)
library(ggplot2)
#library(lubridate)
library(data.table)
library(stringdist)
library(pbmcapply)
#library(plyr)
# Define Date
current_date=format(Sys.time(), "%Y-%m-%d")
current_date=as.Date(current_date)
# Open Google Analytics
account_list <- ga_account_list()
ga_id <- account_list$viewId[1]
#
# Setup script
#
name=''
## Specify Search terms
max = 4000
met = c("sessions",
#"pageviews",
'timeOnPage','avgTimeOnPage',
"entrances","bounces", 'exitRate')
dim = c("date",
"ga:dimension1",
#'ga:dimension2',
#'region',
#'city',
'pagePath'
)
# the function
df2 = data.frame()
get_data <- function(vid, from, to, dim, met, max) {
df <- google_analytics(viewId = vid, date_range = c(from, to), metrics = met,  dimensions = dim,
#met_filters = fc,
dim_filters = fc2,  max = max	,anti_sample = TRUE)
# clean up and set class
df$dimension1 = gsub('O&#039;Toole', "O'Toole", df$dimension1)
df$author_full=df$dimension1
df$dimension1 <- NULL
df$author=name
df$co_authors = gsub(name, '', df$author_full)
df$co_authors = gsub("^,*|(?<=,),|,*$", "", df$co_authors, perl=T)
df$co_authors=gsub(', , ', ', ', df$co_authors)
df$co_authors=trimws(df$co_authors)
df$collaboration_yn=ifelse(df$author==df$author_full,"Sole Author",
ifelse(df$author!=df$author_full|!is.na(df$co_authors),"Co-Authored",0))
df}
gadata <- get_data(vid=vid, from=from, to=to, dim=dim, met=met, max=max)
# view id of your Google Analytics view where 1 conversion = visit
vid <- "3016983"
# date range
from <- "2014-06-30"
to   <- as.character(current_date)
## create filters on dimensions
dimf <- dim_filter("dimension1","PARTIAL", expressions=name,not = F, caseSensitive = F)
dimf2 <- dim_filter("countryIsoCode","EXACT","US",not = F)
fc2 <- filter_clause_ga4(list(dimf #,dimf2
), operator = "OR")
# Build file name
from_s = (from)
from_m = as.character(from)
from_y=str_sub(from, start=3, end = 4)
from_m=str_sub(from, start=6, end = 7)
to_y=str_sub(to, start=3, end = 4)
to_m=str_sub(to, start=6, end = 7)
analysis_range=paste0("(",from_m,from_y,'-',to_m,to_y,")")
initials <- function(a, b){
a <- str_split(a, "&")
a1 <- lapply(a, function(x){
x1 <- str_split(str_trim(x), " ")
paste0(unlist(lapply(x1, str_sub, 1, 2)), collapse="")
})
paste0(unlist(a1), b)
}
analysis_identifier=initials(name,analysis_range)
name=''
## Specify Search terms
max = 4000
met = c("sessions",
#"pageviews",
'timeOnPage','avgTimeOnPage',
"entrances","bounces", 'exitRate')
dim = c("date",
"ga:dimension1",
#'ga:dimension2',
#'region',
#'city',
'pagePath'
)
# the function
df2 = data.frame()
get_data <- function(vid, from, to, dim, met, max) {
df <- google_analytics(viewId = vid, date_range = c(from, to), metrics = met,  dimensions = dim,
#met_filters = fc,
dim_filters = fc2,  max = max	,anti_sample = TRUE)
# clean up and set class
df$dimension1 = gsub('O&#039;Toole', "O'Toole", df$dimension1)
df$author_full=df$dimension1
df$dimension1 <- NULL
df$author=name
df$co_authors = gsub(name, '', df$author_full)
df$co_authors = gsub("^,*|(?<=,),|,*$", "", df$co_authors, perl=T)
df$co_authors=gsub(', , ', ', ', df$co_authors)
df$co_authors=trimws(df$co_authors)
df$collaboration_yn=ifelse(df$author==df$author_full,"Sole Author",
ifelse(df$author!=df$author_full|!is.na(df$co_authors),"Co-Authored",0))
df}
gadata <- get_data(vid=vid, from=from, to=to, dim=dim, met=met, max=max)
# view id of your Google Analytics view where 1 conversion = visit
vid <- "3016983"
# date range
#from <- "2014-06-30"
from <- "2018-01-01"
to   <- as.character(current_date)
## create filters on dimensions
dimf <- dim_filter("dimension1","PARTIAL", expressions=name,not = F, caseSensitive = F)
dimf2 <- dim_filter("countryIsoCode","EXACT","US",not = F)
fc2 <- filter_clause_ga4(list(dimf #,dimf2
), operator = "OR")
# Build file name
from_s = (from)
from_m = as.character(from)
from_y=str_sub(from, start=3, end = 4)
from_m=str_sub(from, start=6, end = 7)
to_y=str_sub(to, start=3, end = 4)
to_m=str_sub(to, start=6, end = 7)
analysis_range=paste0("(",from_m,from_y,'-',to_m,to_y,")")
initials <- function(a, b){
a <- str_split(a, "&")
a1 <- lapply(a, function(x){
x1 <- str_split(str_trim(x), " ")
paste0(unlist(lapply(x1, str_sub, 1, 2)), collapse="")
})
paste0(unlist(a1), b)
}
analysis_identifier=initials(name,analysis_range)
name=''
## Specify Search terms
max = 4000
met = c("sessions",
#"pageviews",
'timeOnPage','avgTimeOnPage',
"entrances","bounces", 'exitRate')
dim = c("date",
"ga:dimension1",
#'ga:dimension2',
#'region',
#'city',
'pagePath'
)
# the function
df2 = data.frame()
get_data <- function(vid, from, to, dim, met, max) {
df <- google_analytics(viewId = vid, date_range = c(from, to), metrics = met,  dimensions = dim,
#met_filters = fc,
dim_filters = fc2,  max = max	,anti_sample = TRUE)
# clean up and set class
df$dimension1 = gsub('O&#039;Toole', "O'Toole", df$dimension1)
df$author_full=df$dimension1
df$dimension1 <- NULL
df$author=name
df$co_authors = gsub(name, '', df$author_full)
df$co_authors = gsub("^,*|(?<=,),|,*$", "", df$co_authors, perl=T)
df$co_authors=gsub(', , ', ', ', df$co_authors)
df$co_authors=trimws(df$co_authors)
df$collaboration_yn=ifelse(df$author==df$author_full,"Sole Author",
ifelse(df$author!=df$author_full|!is.na(df$co_authors),"Co-Authored",0))
df}
gadata <- get_data(vid=vid, from=from, to=to, dim=dim, met=met, max=max)
df1 = as.data.frame(gadata)
View(df1)
unique(df1$author_full)
ClosestMatch2 = function(string, stringVector){
stringVector[amatch(string, stringVector, maxDist=Inf)]}
for(i in seq_along(x)){
webset.names[i] <- ClosestMatch2(i, scholars$users.names)
}
for(i in seq_along(scholars$users.names)){
webset.names[i] <- ClosestMatch2(i, scholars$users.names)
}
for(i in seq_along(scholars$users.names)){
webset.names[i] = ClosestMatch2(i, scholars$users.names)
}
website.names = ""
for(i in seq_along(scholars$users.names)){
website.names[i] = ClosestMatch2(i, scholars$users.names)
}
website.names
seq_along(scholars$users.names)
scholars$users.names
for(i in length(scholars$users.names)){
website.names[i] = ClosestMatch2(i, scholars$users.names)
}
website.names
website.names = list()
for(i in length(scholars$users.names)){
website.names[i] = ClosestMatch2(i, scholars$users.names)
}
website.names
for(i in seq_along(scholars$users.names)){
website.names[i] = ClosestMatch2(i, df1$author_full)
}
website.names
seq_along(scholars$users.names)
for(i in seq_along(scholars$users.names)){
temp=scholars$users.names[i]
website.names[i] = ClosestMatch2(temp[i], df1$author_full)
}
source('~/Desktop/Welfare_Policy/Data/Data_Explorations/Google_Analytics(Cato)/Explore.R', echo=TRUE)
df1$author_full
website.names
temp
for(i in seq_along(scholars$users.names)){
temp=scholars$users.names[i]
website.names[i] = ClosestMatch2(temp, df1$author_full)
}
website.names
scholars$name.website=website.names
scholars$name.website
scholars=as.dataframe(scholars)
scholars=as.data.frame(scholars)
# Twitter Scraping
library(rjson)
library(twitteR)
library(ROAuth)
library(httr)
library(XML)
library(anytime)
library(syuzhet)
#library(reticulate)
#os <- import("os")
# Set API Keys
access_token   =   '3705111012-0ZSGhm0Y5XDkptTYfecD8TwXoJTepfQ6fgtkUX2'
access_token_secret  =  'i3EaK25UsGsHvnhJzvyLxTnVOAMusH5giu0oOKf3Y0pJY'
consumer_key = 'kI3TDGtYDpdN5mPWVtZg4E74L'
consumer_secret  = 'Lk9upIVEm5BsiQq1o3KalWDWLxHL2hFnRlzwDJAkIGnSUvkr6Y'
setup_twitter_oauth(consumer_key, consumer_secret,access_token, access_token_secret)
cato_feeds= 'cato-twitter-feeds'
twlist= "cato-policy-scholars"
twowner= "CatoInstitute"
api.url= paste0("https://api.twitter.com/1.1/lists/members.json?slug=",twlist,"&owner_screen_name=",twowner,"&count=5000")
response <- GET(api.url, config(token=twitteR:::get_oauth_sig()))
response
#cato-twitter-feeds
response.list <- fromJSON(content(response, as = "text", encoding = "UTF-8"))
users.names <- sapply(response.list$users, function(i) i$name)
users.screennames <- sapply(response.list$users, function(i) i$screen_name)
users.IDs <- sapply(response.list$users, function(i) i$id_str)
faves <- sapply(response.list$users, function(i) i$favourites_count)
followers <- sapply(response.list$users, function(i) i$followers_count)
date_created <- sapply(response.list$users, function(i) i$created_at)
cato_twitter=cbind(users.names,date_created,users.screennames,users.IDs,faves,followers)
names(scholars)[names(scholars) == 'users.names'] ='name.twitter'
names(scholars)[names(scholars) == 'users.IDs'] ='ID.twitter'
names(scholars)[names(scholars) == 'users.screennames'] ='handle.twitter'
ClosestMatch2 =  function(string, stringVector){
stringVector[amatch(string, stringVector, maxDist=Inf)]}
website.names = list()
for(i in seq_along(scholars$users.names)){
temp=scholars$users.names[i]
website.names[i] = ClosestMatch2(temp, df1$author_full)
}
scholars$name.website=website.names
scholars=as.data.frame(scholars)
write.csv(cato_twitter, "Cato_Scholars.csv")
for(i in seq_along(scholars$users.names)){
temp=scholars$users.names[i]
website.names[i] = ClosestMatch2(temp, df1$author_full)
}
website.names
for(i in seq_along(scholars$users.names)){
temp=scholars$users.names[i]
website.names[i] = ClosestMatch2(temp, df1$author_full)
}
scholars$users.names
response.list <- fromJSON(content(response, as = "text", encoding = "UTF-8"))
users.names <- sapply(response.list$users, function(i) i$name)
users.screennames <- sapply(response.list$users, function(i) i$screen_name)
users.IDs <- sapply(response.list$users, function(i) i$id_str)
faves <- sapply(response.list$users, function(i) i$favourites_count)
followers <- sapply(response.list$users, function(i) i$followers_count)
date_created <- sapply(response.list$users, function(i) i$created_at)
cato_twitter=cbind(users.names,date_created,users.screennames,users.IDs,faves,followers)
names(scholars)[names(scholars) == 'users.names'] ='name.twitter'
names(scholars)[names(scholars) == 'users.IDs'] ='ID.twitter'
names(scholars)[names(scholars) == 'users.screennames'] ='handle.twitter'
ClosestMatch2 =  function(string, stringVector){
stringVector[amatch(string, stringVector, maxDist=Inf)]}
website.names = list()
cato_twitter
for(i in seq_along(scholars$users.names)){
temp=scholars$users.names[i]
website.names[i] = ClosestMatch2(temp, df1$author_full)
}
scholars$users.names
View(scholars)
scholars=cato_twitter
names(scholars)[names(scholars) == 'users.names'] ='name.twitter'
names(scholars)[names(scholars) == 'users.IDs'] ='ID.twitter'
names(scholars)[names(scholars) == 'users.screennames'] ='handle.twitter'
ClosestMatch2 =  function(string, stringVector){
stringVector[amatch(string, stringVector, maxDist=Inf)]}
for(i in seq_along(scholars$users.names)){
temp=scholars$users.names[i]
website.names[i] = ClosestMatch2(temp, df1$author_full)
}
scholars$name.website=website.names
scholars=as.data.frame(scholars)
write.csv(cato_twitter, "Cato_Scholars.csv")
View(scholars)
scholars
library(rjson)
library(twitteR)
library(ROAuth)
library(httr)
library(XML)
library(anytime)
library(syuzhet)
#library(reticulate)
#os <- import("os")
# Set API Keys
access_token   =   '3705111012-0ZSGhm0Y5XDkptTYfecD8TwXoJTepfQ6fgtkUX2'
access_token_secret  =  'i3EaK25UsGsHvnhJzvyLxTnVOAMusH5giu0oOKf3Y0pJY'
consumer_key = 'kI3TDGtYDpdN5mPWVtZg4E74L'
consumer_secret  = 'Lk9upIVEm5BsiQq1o3KalWDWLxHL2hFnRlzwDJAkIGnSUvkr6Y'
setup_twitter_oauth(consumer_key, consumer_secret,access_token, access_token_secret)
cato_feeds= 'cato-twitter-feeds'
twlist= "cato-policy-scholars"
twowner= "CatoInstitute"
api.url= paste0("https://api.twitter.com/1.1/lists/members.json?slug=",twlist,"&owner_screen_name=",twowner,"&count=5000")
response <- GET(api.url, config(token=twitteR:::get_oauth_sig()))
response
response.list <- fromJSON(content(response, as = "text", encoding = "UTF-8"))
users.names <- sapply(response.list$users, function(i) i$name)
users.screennames <- sapply(response.list$users, function(i) i$screen_name)
users.IDs <- sapply(response.list$users, function(i) i$id_str)
faves <- sapply(response.list$users, function(i) i$favourites_count)
followers <- sapply(response.list$users, function(i) i$followers_count)
date_created <- sapply(response.list$users, function(i) i$created_at)
cato_twitter=cbind(users.names,date_created,users.screennames,users.IDs,faves,followers)
cato_twitter
scholars=cato_twitter
scholars
names(scholars)[names(scholars) == 'users.names'] ='name.twitter'
names(scholars)[names(scholars) == 'users.IDs'] ='ID.twitter'
names(scholars)[names(scholars) == 'users.screennames'] ='handle.twitter'
ClosestMatch2 =  function(string, stringVector){
stringVector[amatch(string, stringVector, maxDist=Inf)]}
for(i in seq_along(scholars$users.names)){
temp=scholars$users.names[i]
website.names[i] = ClosestMatch2(temp, df1$author_full)
}
website.names=list()
for(i in seq_along(scholars$users.names)){
temp=scholars$users.names[i]
website.names[i] = ClosestMatch2(temp, df1$author_full)
}
